{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76birWof94cN"
   },
   "source": [
    "#**Trabajando con Expresiones Regulares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVfm_J7yn1UY"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNc5-kNJoMNf"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P91ofNljoYLV"
   },
   "outputs": [],
   "source": [
    "# Puedes cambiar tu directorio de trabajo:\n",
    "%cd \"/content/drive/My Drive/data/books/\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_C_y8GHpXS9"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyBIirCvq-vm"
   },
   "outputs": [],
   "source": [
    "import nltk  \n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDcVU7fmrD-w"
   },
   "outputs": [],
   "source": [
    "f = open(\"kafka_metamorphosis.txt\", \"r\")\n",
    "story = f.read()\n",
    "story          # string que contiene todo el documento (cuento) de Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-vkXD7ItrVcm"
   },
   "outputs": [],
   "source": [
    "len(story)  # Total de caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFMlgKF1sRJH"
   },
   "source": [
    "###Tokenizemos el documento por oraciones y estas a su vez por palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tj4kzFEFsGb0"
   },
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(text=story, language='english') \n",
    "sents[0:7]     # observa que en estos ejemplos identifica el final de una frase por el \".\" o \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9CUZtISt_Au"
   },
   "source": [
    "### Podemos también generar el documento como una lista de palabras usando el método append. \n",
    "\n",
    "### En este mismo paso podemos aprovechar para transformar todos los caracteres a minúsculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIrugWdztoxF"
   },
   "outputs": [],
   "source": [
    "doc = []\n",
    "for sent in sents:\n",
    "  x = str(sent).split()   # separando por palabras cada frase.\n",
    "  for w in x:\n",
    "    doc.append(w.lower())    # agregamos cada palabra en minúsculas al documento.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXtSeNAg_389"
   },
   "source": [
    "#Trabajemos con algunos casos de expresiones regulares (RE).\n",
    "\n",
    "### Recuerda que las RE te ayudarán a buscar cadenas de caracteres específicas, lo cual a su vez te ayudará a preparar el texto de una mejor manera antes de utilizarlo para anlálisis de texto o entrenamiento de algún modelo de aprendizaje.\n",
    "\n",
    "https://docs.python.org/3/howto/regex.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "es9ez7Kn-XI0"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFHggcO6Besj"
   },
   "source": [
    "### Puedes utilizar solamente palabras que estén dentro de un diccionario, eliminando nombres propios de personas, lugares, etc.\n",
    "\n",
    "### En particular, a partir de NLTK se puede utilizar su corpus de documentos en inglés para generar un diccionario de plabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DN53IxmBCFOz"
   },
   "outputs": [],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQPGaHHY-XAV"
   },
   "outputs": [],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKKJ--ra-8an"
   },
   "outputs": [],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3dvk7jc-8XU"
   },
   "outputs": [],
   "source": [
    "wordlist[5000:5030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKjoi08PIA0T"
   },
   "outputs": [],
   "source": [
    "tmp = [w for w in doc if w in wordlist]   # nos quedamos con las palabras de la novela de Kafka que estén también en nuestro diccionario particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3uUh3yzIh2L"
   },
   "outputs": [],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyXDF8PTJG6f"
   },
   "source": [
    "### Observa que uno de los problemas del diccionario es que puede estar incompleto o no contener todas las conjugaciones de una palabra, como se observa a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0iCv-U4Ij_7"
   },
   "outputs": [],
   "source": [
    "print(doc[0:20])\n",
    "print(tmp[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMjRf8ajJ4Dr"
   },
   "source": [
    "### Busquemos por ejemplo todas las palabras que terminen en \"ed\" en la novela de Kafka:\n",
    "\n",
    "re.search(p,s) : busca todos los patrones \"p\" que coincidan dentro del string \"s\".  \n",
    "\n",
    "ed$ : palabras (cadenas string) que terminen en \"ed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJqZktSBJ-5b"
   },
   "outputs": [],
   "source": [
    "eds = [w for w in doc if re.search('ed$', w)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eCGYuv-VHvC"
   },
   "source": [
    "# Otros casos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7sMw4Ea_VM2z"
   },
   "outputs": [],
   "source": [
    "[w for w in doc if re.search('^.t..$', w)]    # string de 4 caracteres cuyo segundo caracter es \"t\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyWl6iOSWmjj"
   },
   "source": [
    "### **Conjunto (set)**\n",
    "\n",
    "A partir del documento podemos generar un conjunto que contenga solamente strings de manera única, es decir, que no incluya repetición de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-fY5RLxW9yy"
   },
   "outputs": [],
   "source": [
    "conj = set(doc)\n",
    "print(len(doc))\n",
    "print(len(conj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDzq80YZWNz1"
   },
   "outputs": [],
   "source": [
    "[w for w in conj if re.search('^g.[eslva][defg]', w)] # inician con \"g\"; 2° caracter el que sea; \n",
    "                                                      # el 3° y 4° los que se indican entre corcheas y del 5° en adelante es opcional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq9tf0aKZX45"
   },
   "source": [
    "### Veamos otras variantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmaN8v6gZkEC"
   },
   "outputs": [],
   "source": [
    "texto = ['hola, Hola, HOOOOooola, hoolaaaa  ,¡hollla!, holaxx, hola!!!, gato, perro, hospital', 'lol, loool, lllooooll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbWmgp3NcyOi"
   },
   "outputs": [],
   "source": [
    "txt = []             \n",
    "for linea in texto:\n",
    "  x = str(linea).split(',')   # para este ejemplo supongamos que separamos las palabras por las comas.\n",
    "  txt.append(x)\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Gv41If5gcYD"
   },
   "source": [
    "Observa que la salida anterior generó espacios en blanco al inicio de algunas palabras. Borremos dichos espacios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnMifUIeiPhz"
   },
   "outputs": [],
   "source": [
    "d1 = []\n",
    "for w in txt[0]:\n",
    "    x = re.sub(\"\\s+\",\"\", w)  # cualquier cantidad de espacios en blanco al inicio se sustituyen por vacío, es decir, se eliminan.\n",
    "    d1.append(x.lower())\n",
    "\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDXkiNAYb5my"
   },
   "outputs": [],
   "source": [
    "[w for w in d1 if re.search('h+o+l+a+', w)]     # podemos eliminar letras repetidas que sabemos no son parte de la palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HEbyoK6kUbK"
   },
   "outputs": [],
   "source": [
    "[re.sub('¡*h+o+l+a+\\w*!*', 'hola', w) for w in d1]    # Recuerda que el caracter \"*\" de cerradura de Kleene indica 0 o más apariciones.\n",
    "                                                      # El \"+\" indica 1 o más apariciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_ED6Ghja9n0"
   },
   "source": [
    "### Veamos algunos casos con números:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZIvRESEbBvy"
   },
   "outputs": [],
   "source": [
    "numeros = ['1978', '2020', '1990', '2001', '2021', '17530', '10-08-2020', '17-may-2010', 'spider-man', '3.14', '1.3', '45.25', '$10.90', '$7.14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsXk-g_RnkbS"
   },
   "outputs": [],
   "source": [
    "[w for w in numeros if re.search('^[0-9]{4}$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmIetNp7oKVZ"
   },
   "outputs": [],
   "source": [
    "[w for w in numeros if re.search('^[0-9]+-[a-z]{3}-[0-9]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mK7yfqeopAfZ"
   },
   "outputs": [],
   "source": [
    "[w for w in numeros if re.search('^[0-9]+\\.[0-9]+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppGN0SQ8pWQB"
   },
   "outputs": [],
   "source": [
    "[w for w in numeros if re.search('^\\$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHj9u-AeHmHv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DOO6Zs5HmE0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6lh59ANKMMA"
   },
   "source": [
    "### Existen documentos precargados en NLTK. En particular veamos las novelas que están en la opción gutenmberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdxLm1AyHmBo"
   },
   "outputs": [],
   "source": [
    "import nltk  \n",
    "nltk.download() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcpCWIXQJ_vH"
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SylFeTsHKbEH"
   },
   "outputs": [],
   "source": [
    "md = nltk.corpus.gutenberg.words('melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VgGrlVeKhS_",
    "outputId": "58976fe3-0066-415e-f5ba-466900140bde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 251,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fgOkzcSLT_W"
   },
   "outputs": [],
   "source": [
    "xx = list(md) # Podemos ponerlos en un tipo de dato más estándar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBNe4JbqLcAV",
    "outputId": "fe809cfe-00b4-4941-efb3-5ab5b85111da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xx)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Clase_topicos_1_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
