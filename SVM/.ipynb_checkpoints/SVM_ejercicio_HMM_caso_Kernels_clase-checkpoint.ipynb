{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCuE4-EKn9gX"
   },
   "source": [
    "# SVM Ejercicio - Hiperplano de Margen Máximo - Casos Kernels\n",
    "\n",
    "Ejercicios basados en el libro Python Data Science Handbook de J.VanderPlas.\n",
    "\n",
    "https://github.com/jakevdp/PythonDataScienceHandbook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cAi3rDATn8iJ"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "#from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # biblioteca para visualización estadística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OQlvEWGozWU"
   },
   "source": [
    "# Caso Kernel Separable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "emUATMZo5Jgf"
   },
   "outputs": [],
   "source": [
    "N=1000  # total de datos a generar.\n",
    "#noisy_data = sklearn.datasets.make_blobs(n_samples=N, n_features=2, centers=[(-4,-4),(4,4)], cluster_std=1.0, random_state=10)  \n",
    "noisy_data = sklearn.datasets.make_circles(n_samples=N, noise=0.1, factor= 0.1, random_state=7)   # factor: Scale factor between inner and outer circle in (0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4Biwjjk5YQy"
   },
   "outputs": [],
   "source": [
    "X, Y = noisy_data\n",
    "Y = Y.reshape(Y.shape[0],1)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stXDH22t5kAN"
   },
   "outputs": [],
   "source": [
    "print(X[0:6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VbVH6PI5mfU"
   },
   "outputs": [],
   "source": [
    "print(Y[0:6,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VqLytIXRC9ED"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(9,7)})   # (width, height) - definiendo el tamaño de las gráficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjRTgfZYM_6g"
   },
   "source": [
    "Podríamos tratar de resolver el problema mediante un conjunto de funciones lineales... aunque no es lo más adecuado en este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcYHakOe5r3j"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=Y, s=20, cmap=plt.cm.Spectral);  # Puntos de ambas clases\n",
    "\n",
    "xhs = np.linspace(-1.0, 1.0)   # Algunas rectas-clasificadores lineales: Hiperplano/margen Separador\n",
    "for m, b in [(-1, 0.7),  (-0.2, -0.5), (1, -0.7), (2, 0.9)]:\n",
    "    yhs = m * xhs + b\n",
    "    plt.plot(xhs, yhs, '-k');\n",
    "\n",
    "plt.plot([0], [0.6], 'x', color='green',  markersize=10);  # Un punto a clasificar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rssCoQyMfi6l"
   },
   "source": [
    "Se pueden visualizar los puntos 2D desde una persepctiva 3D al aumentar la dimensión de los datos, en este caso podemos suponer un comportamiento tipo gaussiano (simulando una montaña, por ejemplo) mediante una altura \"r\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LS7MjdlgIhl"
   },
   "source": [
    "### Widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8FJlo-50gKtc"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "r = np.exp(-(X ** 2).sum(1))\n",
    "\n",
    "def plot_3D(elev=30, azim=30, X=X, y=Y):\n",
    "    ax = plt.subplot(projection='3d')\n",
    "    ax.scatter3D(X[:, 0], X[:, 1], r, c=y, s=50, cmap=plt.cm.Spectral)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('r')\n",
    "\n",
    "interact(plot_3D, elev=[-90, 0, 20, 30, 45, 60, 70, 90], azip=(-180, 180), X=fixed(X), y=fixed(Y));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Yem7Lho7qjw"
   },
   "source": [
    "### Dibujemos algunas rectas que separen ambas clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KJFmRr-aK8p8"
   },
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True, alfa=0.4):    \n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    \n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 30)\n",
    "    y = np.linspace(ylim[0], ylim[1], 30)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.decision_function(xy).reshape(X.shape)\n",
    "    \n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    \n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=400, facecolors='yellow', alpha=alfa);\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgKGhwXjx8_L"
   },
   "outputs": [],
   "source": [
    "modelk = svm.SVC(kernel='rbf', C=1E10)\n",
    "modelk.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lwWzpxyjli2"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=Y, s=50, cmap=plt.cm.Spectral)\n",
    "plot_svc_decision_function(modelk)\n",
    "plt.scatter(modelk.support_vectors_[:, 0], modelk.support_vectors_[:, 1], s=300, lw=1, facecolors='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE47AwYQPMsD"
   },
   "source": [
    "Veamos las coordenadas de los vectores de soporte resultantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKyqFfJANmSm"
   },
   "outputs": [],
   "source": [
    "modelk.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bO7ICeoF5IuA"
   },
   "source": [
    "# Caso: Kernel - No Separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBRP3sAdOiC9"
   },
   "source": [
    "Veamos ahora el caso no-separable, donde requeriremos de funciones de kernel, en particular veamos el kernel radial gaussiano.\n",
    "\n",
    "Recuerda que en estos casos requerimos del parámetro C asociado a las variables de holgura del método SVM, así como el parámetro gamma asociado a la desviación estándar de la gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIyoX1Kc5Qn9"
   },
   "outputs": [],
   "source": [
    "N=1000\n",
    "noisy_data2 = sklearn.datasets.make_circles(n_samples=N, noise=0.2, factor= 0.1, random_state=7)\n",
    "X2, Y2 = noisy_data2\n",
    "Y2 = Y2.reshape(Y2.shape[0],1)\n",
    "plt.scatter(X2[:,0], X2[:,1], c=Y2, s=20, cmap=plt.cm.Spectral);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYEf_CeH6oTw"
   },
   "outputs": [],
   "source": [
    "#CC, gg = 10E6, 0.01\n",
    "#CC, gg = 100, 0.01\n",
    "CC, gg = 100, 10\n",
    "#CC, gg = 20, 10\n",
    "#CC, gg = 20, 80\n",
    "modelnolk = svm.SVC(kernel='rbf', C=CC, gamma=gg)\n",
    "modelnolk.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2lgZNFRMF9j5"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12,10)}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCX88FuK7NgZ"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X2[:, 0], X2[:, 1], c=Y2, s=50, cmap=plt.cm.Spectral)\n",
    "plot_svc_decision_function(modelnolk, alfa=0.4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SVM_ejercicio_HMM_caso_Kernels_clase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
